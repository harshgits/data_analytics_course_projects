{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict as od\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading in training data\n",
    "\n",
    "X = pd.read_csv('X_train.txt',delim_whitespace=True, header=None).values\n",
    "y = pd.read_csv('Y_train.txt',delim_whitespace=True, header=None).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#X = StandardScaler().fit_transform(X)\n",
    "# WORKS BETTER WITHOUT STANDARDIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating kernel-based Naive Bayes Classifier\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class KDEClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Bayesian generative classification based on KDE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bandwidth : float\n",
    "        the kernel bandwidth within each class\n",
    "    kernel : str\n",
    "        the kernel name, passed to KernelDensity\n",
    "    \"\"\"\n",
    "    def __init__(self, bandwidth=1.0, kernel='gaussian'):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.sort(np.unique(y))\n",
    "        training_sets = [X[y == yi] for yi in self.classes_]\n",
    "        self.models_ = [KernelDensity(bandwidth=self.bandwidth,\n",
    "                                      kernel=self.kernel).fit(Xi)\n",
    "                        for Xi in training_sets]\n",
    "        self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])\n",
    "                           for Xi in training_sets]\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        logprobs = np.array([model.score_samples(X)\n",
    "                             for model in self.models_]).T\n",
    "        result = np.exp(logprobs + self.logpriors_)\n",
    "        return result / result.sum(1, keepdims=True)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search on sample to determine best hyperparameters\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sampling data\n",
    "sample_frac = 1/10.\n",
    "X_sam, _, y_sam, _ = train_test_split(X, y, stratify = y, train_size = sample_frac,\n",
    "                                           random_state = 0)\n",
    "\n",
    "# grid search\n",
    "#kernels = ['gaussian', 'tophat', 'epanechnikov', 'exponential', 'linear', 'cosine']\n",
    "kernels = ['gaussian']\n",
    "bandwidths = 10 ** np.linspace(-1, 1.1, 10)\n",
    "grid = GridSearchCV(KDEClassifier(), od([('kernel', kernels), ('bandwidth', bandwidths)]),\n",
    "                   n_jobs = 8, verbose = 10)\n",
    "grid.fit(X_sam, y_sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting accurac vs hyperparameters\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "cv_results = grid.cv_results_\n",
    "\n",
    "scores_shaped = np.empty(shape = (len(bandwidths), len(kernels)))\n",
    "for dic_ix, dic in enumerate(cv_results['params']):\n",
    "    ker_ix = kernels.index(dic['kernel'])\n",
    "    band_ix = np.argmin(np.abs(bandwidths - dic['bandwidth']))\n",
    "    scores_shaped[band_ix, ker_ix] = cv_results['mean_test_score'][dic_ix]\n",
    "\n",
    "trace = go.Heatmap(x = kernels,\n",
    "                   y = list(np.vectorize(lambda b: 'bw ' + '{0:.2f}'.format(b))\n",
    "                            (bandwidths)),\n",
    "                   z = scores_shaped)\n",
    "data=[trace]\n",
    "figure = go.Figure(data = data, layout = go.Layout(title = 'Accuracy (3-fold cross-validated)'))\n",
    "plotly.offline.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters = {'kernel': 'gaussian', 'bandwidth': 0.85769589859089412}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters =', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
